{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**ResNeXt Blocks (Xie et al., 2017):**](https://openaccess.thecvf.com/content_cvpr_2017/papers/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.pdf) is an advancement for sparser connections, extending ResNet with grouped convolutions to enhance efficiency and performance.\n",
    "\n",
    "<div>\n",
    "<img src=\"./imgs/resnext.png\" style=\"width: 800px;\">\n",
    "</div>\n",
    "\n",
    "ResNeXt is an extension of ResNet that introduces grouped convolutions through a hyperparameter called cardinality, allowing the model to learn more diverse features efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:04:44.663125Z",
     "iopub.status.busy": "2025-03-12T03:04:44.662816Z",
     "iopub.status.idle": "2025-03-12T03:04:47.701792Z",
     "shell.execute_reply": "2025-03-12T03:04:47.701082Z",
     "shell.execute_reply.started": "2025-03-12T03:04:44.663100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:04:50.071958Z",
     "iopub.status.busy": "2025-03-12T03:04:50.071560Z",
     "iopub.status.idle": "2025-03-12T03:04:50.078489Z",
     "shell.execute_reply": "2025-03-12T03:04:50.077779Z",
     "shell.execute_reply.started": "2025-03-12T03:04:50.071933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResNeXtBlock(nn.Module):\n",
    "    def __init__(self, in_channels, bottleneck_channels, out_channels, stride=1, cardinality=32):\n",
    "        \"\"\" ResNeXt Block with grouped convolutions. \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 1x1 convolution to reduce channels\n",
    "        self.conv1 = nn.Conv2d(in_channels, bottleneck_channels, kernel_size=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 3x3 grouped convolution with cardinality\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            bottleneck_channels, bottleneck_channels, kernel_size=3, stride=stride, padding=1, groups=cardinality\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
    "\n",
    "        # 1x1 convolution to restore channels\n",
    "        self.conv3 = nn.Conv2d(bottleneck_channels, out_channels, kernel_size=1, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main path\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "\n",
    "        # Add shortcut\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:04:50.080733Z",
     "iopub.status.busy": "2025-03-12T03:04:50.080489Z",
     "iopub.status.idle": "2025-03-12T03:04:50.102678Z",
     "shell.execute_reply": "2025-03-12T03:04:50.102046Z",
     "shell.execute_reply.started": "2025-03-12T03:04:50.080713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, block, layers, cardinality=32, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "        # Channel configurations for the stages\n",
    "        self.channels = [256, 512, 1024, 2048]\n",
    "\n",
    "        # Stem\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Four stages\n",
    "        self.layer1 = self.make_stage(block, 64, self.channels[0], layers[0], stride=1)\n",
    "        self.layer2 = self.make_stage(block, self.channels[0], self.channels[1], layers[1], stride=2)\n",
    "        self.layer3 = self.make_stage(block, self.channels[1], self.channels[2], layers[2], stride=2)\n",
    "        self.layer4 = self.make_stage(block, self.channels[2], self.channels[3], layers[3], stride=2)\n",
    "\n",
    "        # Global average pooling and fully connected layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(self.channels[3], num_classes)\n",
    "\n",
    "    def make_stage(self, block, in_channels, out_channels, num_blocks, stride):\n",
    "        \"\"\"Helper function to create a stage of ResNeXt blocks.\"\"\"\n",
    "        layers = []\n",
    "        bottleneck_channels = out_channels // 4  # Bottleneck ratio of 4\n",
    "        # First block with specified stride\n",
    "        layers.append(block(in_channels, bottleneck_channels, out_channels, stride, self.cardinality))\n",
    "        # Subsequent blocks with stride 1\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(out_channels, bottleneck_channels, out_channels, 1, self.cardinality))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Stem\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Stages\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # Pooling and classification\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:04:50.103610Z",
     "iopub.status.busy": "2025-03-12T03:04:50.103389Z",
     "iopub.status.idle": "2025-03-12T03:04:50.121131Z",
     "shell.execute_reply": "2025-03-12T03:04:50.120390Z",
     "shell.execute_reply.started": "2025-03-12T03:04:50.103591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ResNeXt50(cardinality=32, num_classes=10):\n",
    "    \"\"\"ResNeXt-50: 4 stages with 3, 4, 6, 3 blocks.\"\"\"\n",
    "    return ResNeXt(ResNeXtBlock, [3, 4, 6, 3], cardinality, num_classes)\n",
    "\n",
    "def ResNeXt101(cardinality=32, num_classes=10):\n",
    "    \"\"\"ResNeXt-101: 4 stages with 3, 4, 23, 3 blocks.\"\"\"\n",
    "    return ResNeXt(ResNeXtBlock, [3, 4, 23, 3], cardinality, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:04:50.122040Z",
     "iopub.status.busy": "2025-03-12T03:04:50.121828Z",
     "iopub.status.idle": "2025-03-12T03:05:23.240125Z",
     "shell.execute_reply": "2025-03-12T03:05:23.239485Z",
     "shell.execute_reply.started": "2025-03-12T03:04:50.122021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = utils.CIFAR10DataLoader(batch_size=64, resize=(224, 224))\n",
    "train_loader = data.get_train_loader()\n",
    "test_loader = data.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:05:23.241211Z",
     "iopub.status.busy": "2025-03-12T03:05:23.240921Z",
     "iopub.status.idle": "2025-03-12T04:07:11.170927Z",
     "shell.execute_reply": "2025-03-12T04:07:11.169963Z",
     "shell.execute_reply.started": "2025-03-12T03:05:23.241181Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10 | Train Loss: 2.2122 | Test Loss: 2.2726 | Test Acc: 0.4027\n",
      "Epoch  2/10 | Train Loss: 1.4719 | Test Loss: 1.4267 | Test Acc: 0.5245\n",
      "Epoch  3/10 | Train Loss: 1.2268 | Test Loss: 1.3134 | Test Acc: 0.5940\n",
      "Epoch  4/10 | Train Loss: 1.0395 | Test Loss: 1.1424 | Test Acc: 0.6478\n",
      "Epoch  5/10 | Train Loss: 0.8877 | Test Loss: 1.1420 | Test Acc: 0.6802\n",
      "Epoch  6/10 | Train Loss: 0.7581 | Test Loss: 1.0671 | Test Acc: 0.7154\n",
      "Epoch  7/10 | Train Loss: 0.6502 | Test Loss: 0.8493 | Test Acc: 0.7369\n",
      "Epoch  8/10 | Train Loss: 0.5499 | Test Loss: 1.0137 | Test Acc: 0.7229\n",
      "Epoch  9/10 | Train Loss: 0.4665 | Test Loss: 0.8088 | Test Acc: 0.7280\n",
      "Epoch 10/10 | Train Loss: 0.3924 | Test Loss: 0.9457 | Test Acc: 0.7550\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNeXt50(num_classes=10)\n",
    "model.apply(utils.init_kaiming).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = utils.train_step(train_loader, model, criterion, optimizer, device)\n",
    "    test_loss, test_acc = utils.eval_step(test_loader, model, criterion, device)\n",
    "    print(f\"Epoch {epoch + 1:>{len(str(epochs))}}/{epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Test Loss: {test_loss:.4f} | \"\n",
    "          f\"Test Acc: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
