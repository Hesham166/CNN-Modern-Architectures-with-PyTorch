{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**VGG Network (Simonyan and Zisserman, 2014)**](https://arxiv.org/abs/1409.1556) is a model that makes use of a number of repeating blocks of elements, known for its simplicity and deep stacks of small 3x3 convolution filters.\n",
    "\n",
    "<div style=\"background-color: white; padding: 10px; display: inline-block; width:600px;\">\n",
    "    <img src=\"imgs/VGG.png\" alt=\"VGG Architecture\">\n",
    "</div>\n",
    "\n",
    "> Image Source: [DATAHACKER](https://datahacker.rs/deep-learning-vgg-16-vs-vgg-19/)\n",
    "\n",
    "The VGG architecture has a simple yet effective design. It utilizes small 3×3 convolutional filters, stacked in multiple VGG blocks, with each block followed by a 2×2 max pooling layer to progressively reduce spatial dimensions while increasing depth.\n",
    "\n",
    "The network consists of five convolutional blocks, where the number of filters doubles after each pooling operation, starting from 64 and increasing up to 512. After the convolutional layers, the feature maps are flattened and passed through three fully connected (FC) layers, with the final FC layer applying a softmax activation for classification.\n",
    "\n",
    "VGG is available in multiple versions—VGG-11, VGG-13, VGG-16, and VGG-19—which differ in the number of convolutional layers. Among these, VGG-16 and VGG-19 are the most commonly used. Despite achieving high accuracy, VGG is computationally expensive due to its large number of parameters (~138 million in VGG-16), making it memory-intensive but highly effective for feature extraction and transfer learning. \n",
    "\n",
    "In this notebook we implement a lightweight version of VGG network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, arch, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        conv_blks = []\n",
    "        for (num_convs, in_channels, out_channels) in arch:\n",
    "            conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            *conv_blks,\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "            nn.Linear(128, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        self.net.apply(utils.init_cnn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        print(f\"{'Layer':<25} {'Output Shape':<20}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(f\"{layer.__class__.__name__:<25} {str(tuple(X.shape)):<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                     Output Shape        \n",
      "==================================================\n",
      "Sequential                (1, 16, 112, 112)   \n",
      "Sequential                (1, 32, 56, 56)     \n",
      "Sequential                (1, 64, 28, 28)     \n",
      "Sequential                (1, 64, 14, 14)     \n",
      "Sequential                (1, 128, 7, 7)      \n",
      "Flatten                   (1, 6272)           \n",
      "Linear                    (1, 128)            \n",
      "ReLU                      (1, 128)            \n",
      "Dropout                   (1, 128)            \n",
      "Linear                    (1, 128)            \n",
      "ReLU                      (1, 128)            \n",
      "Dropout                   (1, 128)            \n",
      "Linear                    (1, 10)             \n"
     ]
    }
   ],
   "source": [
    "tiny_arch = (\n",
    "    (1, 3, 16), (1, 16, 32), (1, 32, 64),\n",
    "    (2, 64, 64), (2, 64, 128)\n",
    ")\n",
    "\n",
    "VGG(tiny_arch).layer_summary((1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.CIFAR10DataLoader(batch_size=64, resize=(224, 224))\n",
    "train_loader = data.get_train_loader()\n",
    "test_loader = data.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss=1.9924904658361469, Test Loss=1.5887233595939199, Test Accuracy=0.424\n",
      "Epoch 2/10: Train Loss=1.563642341310106, Test Loss=1.3630237419893787, Test Accuracy=0.5012\n",
      "Epoch 3/10: Train Loss=1.361630715753721, Test Loss=1.17039374978679, Test Accuracy=0.5786\n",
      "Epoch 4/10: Train Loss=1.2238055544588573, Test Loss=1.0759059509653954, Test Accuracy=0.6181\n",
      "Epoch 5/10: Train Loss=1.1266484316200247, Test Loss=0.9788733986532612, Test Accuracy=0.6625\n",
      "Epoch 6/10: Train Loss=1.0417423496008529, Test Loss=0.9685866798564886, Test Accuracy=0.6659\n",
      "Epoch 7/10: Train Loss=0.9745808902299008, Test Loss=0.8944820943911365, Test Accuracy=0.6924\n",
      "Epoch 8/10: Train Loss=0.9239050871728326, Test Loss=0.8756664566173675, Test Accuracy=0.6957\n",
      "Epoch 9/10: Train Loss=0.8870430824244419, Test Loss=0.8646834974835633, Test Accuracy=0.7023\n",
      "Epoch 10/10: Train Loss=0.8431263513805921, Test Loss=0.8366192784279015, Test Accuracy=0.7159\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VGG(tiny_arch, num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = utils.train_step(train_loader, model, criterion, optimizer, device)\n",
    "    test_loss, test_acc = utils.eval_step(test_loader, model, criterion, device)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}: Train Loss={train_loss}, Test Loss={test_loss}, Test Accuracy={test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
