{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt1TMp0ylnmq"
      },
      "source": [
        "[**VGG Network (Simonyan and Zisserman, 2014)**](https://arxiv.org/abs/1409.1556) is a model that makes use of a number of repeating blocks of elements, known for its simplicity and deep stacks of small 3x3 convolution filters.\n",
        "\n",
        "<div style=\"background-color: white; padding: 10px; display: inline-block; width:400px;\">\n",
        "    <img src=\"imgs/VGG.png\" alt=\"VGG Architecture\">\n",
        "</div>\n",
        "\n",
        "[VGG Architecture](https://datahacker.rs/deep-learning-vgg-16-vs-vgg-19/)\n",
        "\n",
        "The VGG architecture has a simple yet effective design. It utilizes small 3×3 convolutional filters, stacked in multiple VGG blocks, with each block followed by a 2×2 max pooling layer to progressively reduce spatial dimensions while increasing depth.\n",
        "\n",
        "The network consists of five convolutional blocks, where the number of filters doubles after each pooling operation, starting from 64 and increasing up to 512. After the convolutional layers, the feature maps are flattened and passed through three fully connected (FC) layers, with the final FC layer applying a softmax activation for classification.\n",
        "\n",
        "VGG is available in multiple versions—VGG-11, VGG-13, VGG-16, and VGG-19—which differ in the number of convolutional layers. Among these, VGG-16 and VGG-19 are the most commonly used. Despite achieving high accuracy, VGG is computationally expensive due to its large number of parameters (~138 million in VGG-16), making it memory-intensive but highly effective for feature extraction and transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WndaejETlnms"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TSf20i3Ylnmt"
      },
      "outputs": [],
      "source": [
        "VGG_CONFIGS = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K4qdFEwxlnmt"
      },
      "outputs": [],
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, config, num_classes=10, batch_norm=False):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            self._make_layers(config, batch_norm),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 7 * 7, 4096), nn.ReLU(True), nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096), nn.ReLU(True), nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "    def _make_layers(self, config, batch_norm):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in config:\n",
        "            if v == 'M':\n",
        "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            else:\n",
        "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "                if batch_norm:\n",
        "                    layers.extend([conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)])\n",
        "                else:\n",
        "                    layers.extend([conv2d, nn.ReLU(inplace=True)])\n",
        "                in_channels = v\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oqmAb1klnmt",
        "outputId": "de8fdd83-530e-4155-f5fb-2501e7345086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (1, 3, 224, 224)\n",
            "----------------------------------------\n",
            "Conv2d          output shape: (1, 64, 224, 224)\n",
            "BatchNorm2d     output shape: (1, 64, 224, 224)\n",
            "ReLU            output shape: (1, 64, 224, 224)\n",
            "MaxPool2d       output shape: (1, 64, 112, 112)\n",
            "Conv2d          output shape: (1, 128, 112, 112)\n",
            "BatchNorm2d     output shape: (1, 128, 112, 112)\n",
            "ReLU            output shape: (1, 128, 112, 112)\n",
            "MaxPool2d       output shape: (1, 128, 56, 56)\n",
            "Conv2d          output shape: (1, 256, 56, 56)\n",
            "BatchNorm2d     output shape: (1, 256, 56, 56)\n",
            "ReLU            output shape: (1, 256, 56, 56)\n",
            "Conv2d          output shape: (1, 256, 56, 56)\n",
            "BatchNorm2d     output shape: (1, 256, 56, 56)\n",
            "ReLU            output shape: (1, 256, 56, 56)\n",
            "MaxPool2d       output shape: (1, 256, 28, 28)\n",
            "Conv2d          output shape: (1, 512, 28, 28)\n",
            "BatchNorm2d     output shape: (1, 512, 28, 28)\n",
            "ReLU            output shape: (1, 512, 28, 28)\n",
            "Conv2d          output shape: (1, 512, 28, 28)\n",
            "BatchNorm2d     output shape: (1, 512, 28, 28)\n",
            "ReLU            output shape: (1, 512, 28, 28)\n",
            "MaxPool2d       output shape: (1, 512, 14, 14)\n",
            "Conv2d          output shape: (1, 512, 14, 14)\n",
            "BatchNorm2d     output shape: (1, 512, 14, 14)\n",
            "ReLU            output shape: (1, 512, 14, 14)\n",
            "Conv2d          output shape: (1, 512, 14, 14)\n",
            "BatchNorm2d     output shape: (1, 512, 14, 14)\n",
            "ReLU            output shape: (1, 512, 14, 14)\n",
            "MaxPool2d       output shape: (1, 512, 7, 7)\n",
            "Flatten         output shape: (1, 25088)\n",
            "Linear          output shape: (1, 4096)\n",
            "ReLU            output shape: (1, 4096)\n",
            "Dropout         output shape: (1, 4096)\n",
            "Linear          output shape: (1, 4096)\n",
            "ReLU            output shape: (1, 4096)\n",
            "Dropout         output shape: (1, 4096)\n",
            "Linear          output shape: (1, 10)\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "utils.layer_summary(VGG(VGG_CONFIGS['VGG11'], num_classes=10, batch_norm=True), (1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlKv48_blnmu",
        "outputId": "e51f992e-8be8-4087-8c1b-3345ae75bce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "data = utils.CIFAR10DataLoader(batch_size=64, resize=(224, 224))\n",
        "train_loader = data.get_train_loader()\n",
        "test_loader = data.get_test_loader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQjbiPvJlnmu",
        "outputId": "624cf9ac-0a68-4030-8ddf-b79b17368919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1/10 | Train Loss: 2.7673 | Test Loss: 2.3030 | Test Acc: 0.0999\n",
            "Epoch  2/10 | Train Loss: 2.3016 | Test Loss: 2.3025 | Test Acc: 0.1002\n",
            "Epoch  3/10 | Train Loss: 2.2883 | Test Loss: 2.2068 | Test Acc: 0.1547\n",
            "Epoch  4/10 | Train Loss: 2.1872 | Test Loss: 2.0891 | Test Acc: 0.2200\n",
            "Epoch  5/10 | Train Loss: 1.9889 | Test Loss: 1.8015 | Test Acc: 0.3026\n",
            "Epoch  6/10 | Train Loss: 1.7663 | Test Loss: 1.5292 | Test Acc: 0.4344\n",
            "Epoch  7/10 | Train Loss: 1.5529 | Test Loss: 1.4135 | Test Acc: 0.4889\n",
            "Epoch  8/10 | Train Loss: 1.3069 | Test Loss: 1.1412 | Test Acc: 0.5998\n",
            "Epoch  9/10 | Train Loss: 1.1188 | Test Loss: 0.9823 | Test Acc: 0.6610\n",
            "Epoch 10/10 | Train Loss: 0.9599 | Test Loss: 0.8385 | Test Acc: 0.7132\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VGG(VGG_CONFIGS['VGG11'], num_classes=10, batch_norm=True)\n",
        "model.apply(utils.init_kaiming).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = utils.train_step(train_loader, model, criterion, optimizer, device)\n",
        "    test_loss, test_acc = utils.eval_step(test_loader, model, criterion, device)\n",
        "    print(f\"Epoch {epoch + 1:>{len(str(epochs))}}/{epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | \"\n",
        "          f\"Test Loss: {test_loss:.4f} | \"\n",
        "          f\"Test Acc: {test_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}